{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMSI_Data_Science_Workshop_Day_2_Exercises_Part_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH5behQNLERg"
      },
      "source": [
        "## Exercise 4: #YOLO ALMA\n",
        "\n",
        "\n",
        "**Warning: This problem will take a variable amount of time to setup depending on the time of day!**\n",
        "\n",
        "In this exercise, we'll try to classify everyday objects from the\n",
        "[Alma webcam](https://illinois.edu/about/almacam.html) using the [You Only Look Once (YOLO) v3](https://pjreddie.com/darknet/yolo/).\n",
        "\n",
        "(Fun fact, there's another web camera on the quad called \"[the Quadcam](https://illinois.edu/about/quadcam.html)\", but the resolution is problematic with this algorithm.)\n",
        "\n",
        "Prior to beginning this problem, please make sure that a **GPU is enabled** by going to:\n",
        "\n",
        "```\n",
        "Runtime -> Change runtime type -> Hardware Accelerator -> GPU\n",
        "```\n",
        "\n",
        "Next, please run the following setup code to setup the environment for predicting with YOLO v3. In-depth instructions follow immediately after the setup code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVn4-8P7NvHO"
      },
      "source": [
        "## Setup Code \n",
        "\n",
        "Portions of the setup code are based on [yolov3-tf2](https://colab.research.google.com/github/zzh8829/yolov3-tf2/blob/master/colab_gpu.ipynb) document. Further modifications were made to simply the process of initializing the model and stablize the model across tensorflow versions. Please run each code chunk in order. Failure to do so may result in issues when trying to detect an image with YOLO v3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb9R9VDsNvHP"
      },
      "source": [
        "# Suppress output\n",
        "%%capture\n",
        "\n",
        "# 1. Setup the model environment\n",
        "!git clone https://github.com/zzh8829/yolov3-tf2\n",
        "# Switch into the model directory\n",
        "%cd yolov3-tf2/\n",
        "\n",
        "# Install additional packages (note, we avoid using the included requirements.txt)\n",
        "!pip install opencv-python==4.1.1.26 lxml tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqbIJMPVNvHP"
      },
      "source": [
        "# Suppress output\n",
        "%%capture\n",
        "\n",
        "# 2. Retrieve the pretrained model\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights -O data/yolov3.weights\n",
        "!python convert.py"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYuMm4veNvHQ",
        "outputId": "85b4ee09-7dfc-46b0-ca3e-d8c14549a175"
      },
      "source": [
        "# Verify we are in the yolov3-tf2 directory\n",
        "!pwd \n",
        "# Failure to do so will result in checkpoints not being found.\n",
        "\n",
        "# Check contents of the yolov3-tf2 directory\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov3-tf2\n",
            "checkpoints\t data\t\t  README.md\t\ttrain.py\n",
            "colab_gpu.ipynb  detect.py\t  requirements-gpu.txt\tyolov3_tf2\n",
            "conda-cpu.yml\t detect_video.py  requirements.txt\n",
            "conda-gpu.yml\t docs\t\t  setup.py\n",
            "convert.py\t LICENSE\t  tools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsHCsTohNvHQ",
        "outputId": "44d88d4b-5beb-48b2-f630-ce27196622a1"
      },
      "source": [
        "# 3. Structure the YOLO model \n",
        "import sys\n",
        "from absl import app, logging, flags\n",
        "from absl.flags import FLAGS\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import requests\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from yolov3_tf2.models import (\n",
        "    YoloV3, YoloV3Tiny\n",
        ")\n",
        "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
        "from yolov3_tf2.utils import draw_outputs\n",
        "\n",
        "# Ensure no duplicate flags exist if code chunk is re-run multiple times.\n",
        "def del_all_flags():\n",
        "    for name in list(flags.FLAGS):\n",
        "        if name in ['classes', 'weights', 'tiny',\n",
        "                    'size', 'image', 'tfrecord', 'output',\n",
        "                    'num_classes']: \n",
        "            delattr(flags.FLAGS, name)\n",
        "\n",
        "del_all_flags()\n",
        "# Remove flags\n",
        "\n",
        "# Define set of flags required for processing data.\n",
        "flags.DEFINE_string('classes', './data/coco.names', 'path to classes file')\n",
        "flags.DEFINE_string('weights', './checkpoints/yolov3.tf',\n",
        "                    'path to weights file')\n",
        "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
        "flags.DEFINE_integer('size', 416, 'resize images to')\n",
        "flags.DEFINE_string('image', './data/girl.png', 'path to input image')\n",
        "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
        "flags.DEFINE_string('output', './output.jpg', 'path to output image')\n",
        "flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')\n",
        "\n",
        "# Explicitly request flags be parsed prior to accessing them in the next code chunk.\n",
        "# https://github.com/google/python-gflags/issues/37#issuecomment-297800637\n",
        "FLAGS([sys.argv])\n",
        "\n",
        "## Change if needed to allow for classification with lower probabilities\n",
        "## in exercise (b) \n",
        "FLAGS.yolo_score_threshold = 0.5\n",
        "\n",
        "# Verify that a GPU is available\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "  print(\"GPU Detected ...\")\n",
        "else:\n",
        "  print(\"GPU not found ... \\n\\\n",
        "         Please make sure to enable a GPU prior to continuing.\\n\\\n",
        "         Follow notes at the start of the problem\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Detected ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jGamJUqNvHS",
        "outputId": "2ea422e2-0df4-4a22-e6c7-2af622bb6c0d"
      },
      "source": [
        "# Bring online the model\n",
        "if FLAGS.tiny:\n",
        "    yolo = YoloV3Tiny(classes=FLAGS.num_classes)\n",
        "else:\n",
        "    yolo = YoloV3(classes=FLAGS.num_classes)\n",
        "\n",
        "# Ensure model loads correctly\n",
        "yolo.load_weights(FLAGS.weights).expect_partial()\n",
        "print('Loaded: weights ... ')\n",
        "\n",
        "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
        "print('Loaded: classes ... ')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: weights ... \n",
            "Loaded: classes ... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LkU38KcNvHS"
      },
      "source": [
        "## (a) Detecting Objects\n",
        "\n",
        "In this exercise, we're interested in detecting within images from the Alma mater webcam these object classes:\n",
        "\n",
        "- person\n",
        "- bicycle\n",
        "- backpack\n",
        "- handbag\n",
        "- cell phone\n",
        "\n",
        "Please use the spelling given above as it matches with classes recognized by the YoloV3 network (see [data/coco.names](https://github.com/pjreddie/darknet/blob/master/data/coco.names) for details.)\n",
        "\n",
        "Obtain the images from:\n",
        "\n",
        " - https://coatless.github.io/alma-cam/alma-cam-1.png\n",
        " - https://coatless.github.io/alma-cam/alma-cam-2.png\n",
        " - https://coatless.github.io/alma-cam/alma-cam-3.png\n",
        " - https://coatless.github.io/alma-cam/alma-cam-4.png\n",
        " - https://coatless.github.io/alma-cam/alma-cam-5.png\n",
        " - https://coatless.github.io/alma-cam/alma-cam-6.png\n",
        " - https://coatless.github.io/alma-cam/alma-cam-7.png\n",
        " - https://coatless.github.io/alma-cam/alma-cam-8.png\n",
        " - https://coatless.github.io/alma-cam/alma-cam-9.png\n",
        " - https://coatless.github.io/alma-cam/alma-cam-10.png\n",
        "\n",
        "So, the first image can be retrieved with:\n",
        "\n",
        "```\n",
        "https://coatless.github.io/alma-cam/alma-cam-1.png\n",
        "```\n",
        "\n",
        "Dynamically construct a Pandas dataframe that contains the ImageID and a count of each object under the given class. e.g.\n",
        "\n",
        "| ImageID    | Person | Bicycle | Backpack | handbag | cell phone   |\n",
        "|:-----------|--------|---------|----------|---------|--------------|\n",
        "| example-1  | 0      |     1   | 1        | 0       |    0         |\n",
        "\n",
        "To help in this endeavor, the author has made available a set of functions to  model with the existing network. Please use these functions to load images and model the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbIK6XcrNvHS"
      },
      "source": [
        "# Retrieve image from online\n",
        "def download_img(url):\n",
        "  return requests.get(url).content\n",
        "\n",
        "# Internal function that pads the image with an additional dimension\n",
        "# such that an image goes from height x width to examples x height x width\n",
        "# and standardize the image with a fixed size\n",
        "def clean_img(img_raw, img_size = FLAGS.size):\n",
        "  # Expand dimension to obtain a single image\n",
        "  img = tf.expand_dims(img_raw, 0)\n",
        "  # Transform image to specific size\n",
        "  img = transform_images(img, img_size)\n",
        "  return img\n",
        "\n",
        "# Load the image downloaded from the internet\n",
        "def load_img_binary(img_dl, channels = 3, img_size = FLAGS.size):\n",
        "  img_raw = tf.image.decode_image(img_dl, channels = channels)\n",
        "  img = clean_img(img_raw, img_size)\n",
        "  return img, img_raw\n",
        "  \n",
        "# Load the image found locally\n",
        "def load_img_file(path, channels = 3, img_size = FLAGS.size):\n",
        "  # Load image file from path\n",
        "  img, img_raw = load_img_binary(open(path, 'rb').read(), \n",
        "                        channels, img_size)\n",
        "  return img, img_raw\n",
        "\n",
        "# Perform a classification with the YOLO network\n",
        "def classify_img(img, yolo):\n",
        "  t1 = time.time()\n",
        "  boxes, scores, classes, nums = yolo(img)\n",
        "  t2 = time.time()\n",
        "  print(f'Elapsed time: {t2 - t1} ...')\n",
        "  return boxes, scores, classes, nums\n",
        "\n",
        "# Traceback of the detections found in the image\n",
        "# Useful for understanding what was detected in a single image\n",
        "def img_detect(boxes, scores, classes, nums, class_names):\n",
        "  print('Detections ...')\n",
        "  for i in range(nums[0]):\n",
        "    classes_found = class_names[int(classes[0][i])]\n",
        "    class_confidence = np.array(scores[0][i])\n",
        "    box_outline = np.array(boxes[0][i])\n",
        "    print(f'\\t{classes_found}, {class_confidence}, {box_outline}')\n",
        "\n",
        "# Render the image with detected object in boxes\n",
        "def img_draw_boxes(img, img_raw, boxes, scores, classes, nums, class_names):\n",
        "  img = cv2.cvtColor(img_raw.numpy(), cv2.COLOR_RGB2BGR)\n",
        "  img = draw_outputs(img, (boxes, scores, classes, nums), class_names)\n",
        "  from IPython.display import Image, display\n",
        "  display(Image(data=bytes(cv2.imencode('.jpg', img)[1]), width=800))\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO3jeFOoNvHT"
      },
      "source": [
        "Consider the following image from a UIUC blog:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "89Ez-b8BNvHT",
        "outputId": "fc85171e-6cf2-4ba3-ec03-135e755be788"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(url='https://blogs.illinois.edu/files/6231/545166/117021.jpg', width=500)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "text/html": [
              "<img src=\"https://blogs.illinois.edu/files/6231/545166/117021.jpg\" width=\"500\"/>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1rUEc5gNvHT"
      },
      "source": [
        "The YOLOv3 algorithm could be used by:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saTlNR2dNvHT"
      },
      "source": [
        "# Example image download and read \n",
        "img, img_raw = load_img_binary(\n",
        "    download_img(\"https://blogs.illinois.edu/files/6231/545166/117021.jpg\")\n",
        ")\n",
        "\n",
        "boxes, scores, classes, nums = classify_img(img, yolo)\n",
        "# img_detect(boxes, scores, classes, nums, class_names)\n",
        "# img_draw_boxes(img, img_raw, boxes, scores, classes, nums, class_names)\n",
        "\n",
        "for i in range(nums[0]):\n",
        "  print(class_names[int(classes[0][i])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y5giGbDRrWL"
      },
      "source": [
        "In the last code statement, we're saving output from the model into four variables:\n",
        "\n",
        "- `boxes`: Bounding box regions of where the object detected lies \n",
        "  - e.g. blue boxes in the above image\n",
        "- `nums`: Number of classifications per image.\n",
        "  - e.g. number of blue boxes in the above image\n",
        "- `scores`: Probabilities of the different classes the model was trained for.\n",
        "  - e.g. the red numeric values in the above image (e.g. top-left is 0.9796)\n",
        "- `classes`: Labels of objects whose `score` exceeded a classification threshold given by `FLAGS.yolo_score_threshold = 0.2`. \n",
        "  - e.g. the red names in the above image (e.g. person)\n",
        "\n",
        "From the above variables, we are only interested in the `nums` and `classes` variables. In particular, we want to know how many items were detected in the image via `nums[0]` and the class that was detected, `classes[0][j]`. We can observe this being the driving influence behind the custom print method in `img_detect()`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbU15WEPNvHU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "033e44a7-374d-4d43-e221-4645537a3393"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "## code here\n",
        "\n",
        "# Consider structuring the problem by:\n",
        "# 1. Generating a list of images\n",
        "# 2. Classifying each image\n",
        "# 3. Storing the results inside of a data.frame\n",
        "\n",
        "url_base = \"https://coatless.github.io/alma-cam/\"\n",
        "urls = [f\"{url_base}/alma-cam-{i}.png\" for i in range(1, 11)]\n",
        "\n",
        "# This makes urls have between:\n",
        "# https://coatless.github.io/alma-cam/alma-cam-1.png\n",
        "\n",
        "# Pre-populate a data frame\n",
        "df_classes = ['person', 'bicycle', 'backpack', 'handbag', 'cell phone']\n",
        "cols = ['ImageID'] + df_classes\n",
        "df = pd.DataFrame(columns = cols,index=range(10))\n",
        "df.loc[: , :] = 0\n",
        "\n",
        "df\n",
        "\n",
        "# Loop over the images here\n",
        "index = 0\n",
        "for url in urls: #shortened for testing\n",
        "    img, img_raw = load_img_binary(download_img(url))\n",
        "    boxes, scores, classes, nums = classify_img(img, yolo)\n",
        "    # current_classes = pd.DataFrame(classes[0])\n",
        "    # display(current_classes)\n",
        "    # print(nums[0])\n",
        "    # img_detect(boxes, scores, classes, nums, class_names)\n",
        "\n",
        "    for kind in df_classes:\n",
        "      i = class_names.index(kind) # where in class_names kind appears\n",
        "      kind_count =   list(classes[0]).count(i)   #how much to increment by\n",
        "      df.loc[index, kind] = kind_count  #incrementing \n",
        "    index += 1\n",
        "\n",
        "display(df)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 0.18337774276733398 ...\n",
            "Elapsed time: 0.10562276840209961 ...\n",
            "Elapsed time: 0.10159826278686523 ...\n",
            "Elapsed time: 0.10455870628356934 ...\n",
            "Elapsed time: 0.10680103302001953 ...\n",
            "Elapsed time: 0.10278582572937012 ...\n",
            "Elapsed time: 0.10720467567443848 ...\n",
            "Elapsed time: 0.11040496826171875 ...\n",
            "Elapsed time: 0.17040681838989258 ...\n",
            "Elapsed time: 0.40252685546875 ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ImageID person bicycle backpack handbag cell phone\n",
              "0       0     11       0        0       0          0\n",
              "1       0      6       0        0       0          0\n",
              "2       0      3       0        0       0          0\n",
              "3       0      4       0        0       0          0\n",
              "4       0      8       0        0       0          0\n",
              "5       0     12       0        0       0          0\n",
              "6       0     14       0        0       0          0\n",
              "7       0     13       0        0       0          0\n",
              "8       0      8       0        0       0          0\n",
              "9       0      9       0        0       0          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29cd7d6e-95b1-4ec3-a66e-3cf93598ef41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageID</th>\n",
              "      <th>person</th>\n",
              "      <th>bicycle</th>\n",
              "      <th>backpack</th>\n",
              "      <th>handbag</th>\n",
              "      <th>cell phone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29cd7d6e-95b1-4ec3-a66e-3cf93598ef41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29cd7d6e-95b1-4ec3-a66e-3cf93598ef41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29cd7d6e-95b1-4ec3-a66e-3cf93598ef41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrOZ8GcgDxVA",
        "outputId": "59fe7706-867d-497a-f6fb-818a02fdcad1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['person',\n",
              " 'bicycle',\n",
              " 'car',\n",
              " 'motorbike',\n",
              " 'aeroplane',\n",
              " 'bus',\n",
              " 'train',\n",
              " 'truck',\n",
              " 'boat',\n",
              " 'traffic light',\n",
              " 'fire hydrant',\n",
              " 'stop sign',\n",
              " 'parking meter',\n",
              " 'bench',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'dog',\n",
              " 'horse',\n",
              " 'sheep',\n",
              " 'cow',\n",
              " 'elephant',\n",
              " 'bear',\n",
              " 'zebra',\n",
              " 'giraffe',\n",
              " 'backpack',\n",
              " 'umbrella',\n",
              " 'handbag',\n",
              " 'tie',\n",
              " 'suitcase',\n",
              " 'frisbee',\n",
              " 'skis',\n",
              " 'snowboard',\n",
              " 'sports ball',\n",
              " 'kite',\n",
              " 'baseball bat',\n",
              " 'baseball glove',\n",
              " 'skateboard',\n",
              " 'surfboard',\n",
              " 'tennis racket',\n",
              " 'bottle',\n",
              " 'wine glass',\n",
              " 'cup',\n",
              " 'fork',\n",
              " 'knife',\n",
              " 'spoon',\n",
              " 'bowl',\n",
              " 'banana',\n",
              " 'apple',\n",
              " 'sandwich',\n",
              " 'orange',\n",
              " 'broccoli',\n",
              " 'carrot',\n",
              " 'hot dog',\n",
              " 'pizza',\n",
              " 'donut',\n",
              " 'cake',\n",
              " 'chair',\n",
              " 'sofa',\n",
              " 'pottedplant',\n",
              " 'bed',\n",
              " 'diningtable',\n",
              " 'toilet',\n",
              " 'tvmonitor',\n",
              " 'laptop',\n",
              " 'mouse',\n",
              " 'remote',\n",
              " 'keyboard',\n",
              " 'cell phone',\n",
              " 'microwave',\n",
              " 'oven',\n",
              " 'toaster',\n",
              " 'sink',\n",
              " 'refrigerator',\n",
              " 'book',\n",
              " 'clock',\n",
              " 'vase',\n",
              " 'scissors',\n",
              " 'teddy bear',\n",
              " 'hair drier',\n",
              " 'toothbrush']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUjsDVpnNvHU"
      },
      "source": [
        "## (b) Upload and run your own image! \n",
        "\n",
        "In this exercise, you will repeat the prior exercise but instead you will select the classes that should be detected from an image you supply.\n",
        "\n",
        "View all possible classes by exploring the [data/coco.names](https://github.com/pjreddie/darknet/blob/master/data/coco.names) class names file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZT73P2ZNvHU",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "a3ae5494-7184-45f5-bc18-778506e28e96"
      },
      "source": [
        "#we didn't have time to get to this one\n",
        "\n",
        "\n",
        "\n",
        "# Upload an image file              \n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c235aab0-0dad-4023-a659-abcbf788da9a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c235aab0-0dad-4023-a659-abcbf788da9a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-4f7351ea94cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Upload an image file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m   \"\"\"\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    121\u001b[0m   result = _output.eval_js(\n\u001b[1;32m    122\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m--> 123\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m    124\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cILfdTU8RYh7"
      },
      "source": [
        "Please use the name of the uploaded file in place of the `colab-logo.png`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va2b7OucNvHU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "113af1fc-610e-437f-fb95-f943a0c41aaa"
      },
      "source": [
        "from IPython.display import Image\n",
        "# Display the embedded image in the notebook.\n",
        "Image('colab-logo.png', width=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "colab-logo.png"
          },
          "metadata": {
            "image/png": {
              "width": 100
            }
          },
          "execution_count": 11
        }
      ]
    }
  ]
}